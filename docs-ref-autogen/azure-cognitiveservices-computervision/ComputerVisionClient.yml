### YamlMime:UniversalReference
items:
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient
    name: ComputerVisionClient
    fullName: ComputerVisionClient
    children:
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.constructor
      - azure-cognitiveservices-computervision.ComputerVisionClient.credentials
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResultWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
    langs:
      - typeScript
    type: class
    summary: ''
    extends:
      name: ServiceClient
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
    name: 'analyzeImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation extracts a rich set of visual features based on the image

      content.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL. Within your request, there is an optional parameter to allow

      you to choose which features to return. By default, image categories are

      returned in the response.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function analyzeImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
    name: 'analyzeImage(string, Object, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation extracts a rich set of visual features based on the image

      content.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL. Within your request, there is an optional parameter to allow

      you to choose which features to return. By default, image categories are

      returned in the response.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function analyzeImage(url: string, options: Object, callback:
        ServiceCallback<ImageAnalysis>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
    name: 'analyzeImage(string, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation extracts a rich set of visual features based on the image

      content.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL. Within your request, there is an optional parameter to allow

      you to choose which features to return. By default, image categories are

      returned in the response.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function analyzeImage(url: string, callback:
        ServiceCallback<ImageAnalysis>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
    name: 'analyzeImageByDomain(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model. The list of domain-specific models that are
      supported

      by the Computer Vision API can be retrieved using the /models GET request.

      Currently, the API provides following domain-specific models: celebrities,

      landmarks.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomain(model: string, url: string, options?:
        Object)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize.
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
    name: >-
      analyzeImageByDomain(string, string, Object,
      ServiceCallback<DomainModelResults>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model. The list of domain-specific models that are
      supported

      by the Computer Vision API can be retrieved using the /models GET request.

      Currently, the API provides following domain-specific models: celebrities,

      landmarks.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomain(model: string, url: string, options:
        Object, callback: ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
    name: 'analyzeImageByDomain(string, string, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model. The list of domain-specific models that are
      supported

      by the Computer Vision API can be retrieved using the /models GET request.

      Currently, the API provides following domain-specific models: celebrities,

      landmarks.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomain(model: string, url: string, callback:
        ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
    name: 'analyzeImageByDomainInStream(string, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model. The list of domain-specific models that are
      supported

      by the Computer Vision API can be retrieved using the /models GET request.

      Currently, the API provides following domain-specific models: celebrities,

      landmarks.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStream(model: string, image:
        stream.Readable, options?: Object)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
    name: >-
      analyzeImageByDomainInStream(string, stream.Readable, Object,
      ServiceCallback<DomainModelResults>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model. The list of domain-specific models that are
      supported

      by the Computer Vision API can be retrieved using the /models GET request.

      Currently, the API provides following domain-specific models: celebrities,

      landmarks.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStream(model: string, image:
        stream.Readable, options: Object, callback:
        ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
    name: >-
      analyzeImageByDomainInStream(string, stream.Readable,
      ServiceCallback<DomainModelResults>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model. The list of domain-specific models that are
      supported

      by the Computer Vision API can be retrieved using the /models GET request.

      Currently, the API provides following domain-specific models: celebrities,

      landmarks.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStream(model: string, image:
        stream.Readable, callback: ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
    name: >-
      analyzeImageByDomainInStreamWithHttpOperationResponse(string,
      stream.Readable, Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model. The list of domain-specific models that are
      supported

      by the Computer Vision API can be retrieved using the /models GET request.

      Currently, the API provides following domain-specific models: celebrities,

      landmarks.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStreamWithHttpOperationResponse(model:
        string, image: stream.Readable, options?: Object)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
    name: 'analyzeImageByDomainWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model. The list of domain-specific models that are
      supported

      by the Computer Vision API can be retrieved using the /models GET request.

      Currently, the API provides following domain-specific models: celebrities,

      landmarks.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainWithHttpOperationResponse(model: string,
        url: string, options?: Object)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize.
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
    name: 'analyzeImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation extracts a rich set of visual features based on the image

      content.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL. Within your request, there is an optional parameter to allow

      you to choose which features to return. By default, image categories are

      returned in the response.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
    name: >-
      analyzeImageInStream(stream.Readable, Object,
      ServiceCallback<ImageAnalysis>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation extracts a rich set of visual features based on the image

      content.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL. Within your request, there is an optional parameter to allow

      you to choose which features to return. By default, image categories are

      returned in the response.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function analyzeImageInStream(image: stream.Readable, options: Object,
        callback: ServiceCallback<ImageAnalysis>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
    name: 'analyzeImageInStream(stream.Readable, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation extracts a rich set of visual features based on the image

      content.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL. Within your request, there is an optional parameter to allow

      you to choose which features to return. By default, image categories are

      returned in the response.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function analyzeImageInStream(image: stream.Readable, callback:
        ServiceCallback<ImageAnalysis>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
    name: 'analyzeImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation extracts a rich set of visual features based on the image

      content.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL. Within your request, there is an optional parameter to allow

      you to choose which features to return. By default, image categories are

      returned in the response.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function analyzeImageInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
    name: 'analyzeImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation extracts a rich set of visual features based on the image

      content.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL. Within your request, there is an optional parameter to allow

      you to choose which features to return. By default, image categories are

      returned in the response.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function analyzeImageWithHttpOperationResponse(url: string, options?:
        Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile
    name: 'batchReadFile(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Use this interface to get the result of a Read operation, employing the

      state-of-the-art Optical Character Recognition (OCR) algorithms optimized

      for text-heavy documents. When you use the Read File interface, the
      response

      contains a field called "Operation-Location". The "Operation-Location"
      field

      contains the URL that you must use for your "Read Operation Result"

      operation to access OCR results.​
    syntax:
      content: 'function batchReadFile(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_2
    name: 'batchReadFile(string, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Use this interface to get the result of a Read operation, employing the

      state-of-the-art Optical Character Recognition (OCR) algorithms optimized

      for text-heavy documents. When you use the Read File interface, the
      response

      contains a field called "Operation-Location". The "Operation-Location"
      field

      contains the URL that you must use for your "Read Operation Result"

      operation to access OCR results.​
    syntax:
      content: >-
        function batchReadFile(url: string, mode: string, options: Object,
        callback: ServiceCallback<void>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_1
    name: 'batchReadFile(string, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Use this interface to get the result of a Read operation, employing the

      state-of-the-art Optical Character Recognition (OCR) algorithms optimized

      for text-heavy documents. When you use the Read File interface, the
      response

      contains a field called "Operation-Location". The "Operation-Location"
      field

      contains the URL that you must use for your "Read Operation Result"

      operation to access OCR results.​
    syntax:
      content: >-
        function batchReadFile(url: string, mode: string, callback:
        ServiceCallback<void>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream
    name: 'batchReadFileInStream(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Use this interface to get the result of a Read Document operation,
      employing

      the state-of-the-art Optical Character Recognition (OCR) algorithms

      optimized for text-heavy documents. When you use the Read Document

      interface, the response contains a field called "Operation-Location". The

      "Operation-Location" field contains the URL that you must use for your
      "Get

      Read Result operation" to access OCR results.​
    syntax:
      content: >-
        function batchReadFileInStream(image: stream.Readable, mode: string,
        options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_2
    name: >-
      batchReadFileInStream(stream.Readable, string, Object,
      ServiceCallback<void>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Use this interface to get the result of a Read Document operation,
      employing

      the state-of-the-art Optical Character Recognition (OCR) algorithms

      optimized for text-heavy documents. When you use the Read Document

      interface, the response contains a field called "Operation-Location". The

      "Operation-Location" field contains the URL that you must use for your
      "Get

      Read Result operation" to access OCR results.​
    syntax:
      content: >-
        function batchReadFileInStream(image: stream.Readable, mode: string,
        options: Object, callback: ServiceCallback<void>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_1
    name: 'batchReadFileInStream(stream.Readable, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Use this interface to get the result of a Read Document operation,
      employing

      the state-of-the-art Optical Character Recognition (OCR) algorithms

      optimized for text-heavy documents. When you use the Read Document

      interface, the response contains a field called "Operation-Location". The

      "Operation-Location" field contains the URL that you must use for your
      "Get

      Read Result operation" to access OCR results.​
    syntax:
      content: >-
        function batchReadFileInStream(image: stream.Readable, mode: string,
        callback: ServiceCallback<void>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStreamWithHttpOperationResponse
    name: >-
      batchReadFileInStreamWithHttpOperationResponse(stream.Readable, string,
      Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Use this interface to get the result of a Read Document operation,
      employing

      the state-of-the-art Optical Character Recognition (OCR) algorithms

      optimized for text-heavy documents. When you use the Read Document

      interface, the response contains a field called "Operation-Location". The

      "Operation-Location" field contains the URL that you must use for your
      "Get

      Read Result operation" to access OCR results.​
    syntax:
      content: >-
        function batchReadFileInStreamWithHttpOperationResponse(image:
        stream.Readable, mode: string, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileWithHttpOperationResponse
    name: 'batchReadFileWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Use this interface to get the result of a Read operation, employing the

      state-of-the-art Optical Character Recognition (OCR) algorithms optimized

      for text-heavy documents. When you use the Read File interface, the
      response

      contains a field called "Operation-Location". The "Operation-Location"
      field

      contains the URL that you must use for your "Read Operation Result"

      operation to access OCR results.​
    syntax:
      content: >-
        function batchReadFileWithHttpOperationResponse(url: string, mode:
        string, options?: Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.constructor
    name: >-
      ComputerVisionClient(ServiceClientCredentials, string,
      ServiceClientOptions)
    children: []
    type: constructor
    langs:
      - typeScript
    summary: ''
    syntax:
      content: >-
        new ComputerVisionClient(credentials: ServiceClientCredentials,
        endpoint: string, options?: ServiceClientOptions)
      parameters:
        - id: credentials
          type:
            - ServiceClientCredentials
          description: >
            Subscription credentials which uniquely identify client
            subscription.
        - id: endpoint
          type:
            - string
          description: |
            Supported Cognitive Services endpoints.
        - id: options
          type:
            - ServiceClientOptions
          description: ''
          optional: true
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.credentials
    name: credentials
    fullName: credentials
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'credentials: ServiceClientCredentials'
      return:
        type:
          - ServiceClientCredentials
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
    name: 'describeImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences. The description is based on a collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image. Descriptions are ordered by

      their confidence score. All descriptions are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function describeImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
    name: 'describeImage(string, Object, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences. The description is based on a collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image. Descriptions are ordered by

      their confidence score. All descriptions are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImage(url: string, options: Object, callback:
        ServiceCallback<ImageDescription>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
    name: 'describeImage(string, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences. The description is based on a collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image. Descriptions are ordered by

      their confidence score. All descriptions are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImage(url: string, callback:
        ServiceCallback<ImageDescription>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
    name: 'describeImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences. The description is based on a collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image. Descriptions are ordered by

      their confidence score. All descriptions are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
    name: >-
      describeImageInStream(stream.Readable, Object,
      ServiceCallback<ImageDescription>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences. The description is based on a collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image. Descriptions are ordered by

      their confidence score. All descriptions are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageInStream(image: stream.Readable, options: Object,
        callback: ServiceCallback<ImageDescription>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
    name: 'describeImageInStream(stream.Readable, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences. The description is based on a collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image. Descriptions are ordered by

      their confidence score. All descriptions are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageInStream(image: stream.Readable, callback:
        ServiceCallback<ImageDescription>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
    name: 'describeImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences. The description is based on a collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image. Descriptions are ordered by

      their confidence score. All descriptions are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
    name: 'describeImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences. The description is based on a collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image. Descriptions are ordered by

      their confidence score. All descriptions are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageWithHttpOperationResponse(url: string, options?:
        Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects
    name: 'detectObjects(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Performs object detection on the specified image.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function detectObjects(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_2
    name: 'detectObjects(string, Object, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Performs object detection on the specified image.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function detectObjects(url: string, options: Object, callback:
        ServiceCallback<DetectResult>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_1
    name: 'detectObjects(string, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Performs object detection on the specified image.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function detectObjects(url: string, callback:
        ServiceCallback<DetectResult>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream
    name: 'detectObjectsInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Performs object detection on the specified image.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function detectObjectsInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_2
    name: >-
      detectObjectsInStream(stream.Readable, Object,
      ServiceCallback<DetectResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Performs object detection on the specified image.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function detectObjectsInStream(image: stream.Readable, options: Object,
        callback: ServiceCallback<DetectResult>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_1
    name: 'detectObjectsInStream(stream.Readable, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Performs object detection on the specified image.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function detectObjectsInStream(image: stream.Readable, callback:
        ServiceCallback<DetectResult>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStreamWithHttpOperationResponse
    name: 'detectObjectsInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Performs object detection on the specified image.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function detectObjectsInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsWithHttpOperationResponse
    name: 'detectObjectsWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Performs object detection on the specified image.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function detectObjectsWithHttpOperationResponse(url: string, options?:
        Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
    name: endpoint
    fullName: endpoint
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'endpoint: string'
      return:
        type:
          - string
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
    name: 'generateThumbnail(number, number, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image.

      A successful response contains the thumbnail image binary. If the request

      failed, the response contains an error code and a message to help
      determine

      what went wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or

      InternalServerError.
    syntax:
      content: >-
        function generateThumbnail(width: number, height: number, url: string,
        options?: Object)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail, in pixels. It must be between
            1 and 1024. Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail, in pixels. It must be
            between 1 and 1024. Recommended minimum of 50.
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
    name: >-
      generateThumbnail(number, number, string, Object,
      ServiceCallback<stream.Readable>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image.

      A successful response contains the thumbnail image binary. If the request

      failed, the response contains an error code and a message to help
      determine

      what went wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or

      InternalServerError.
    syntax:
      content: >-
        function generateThumbnail(width: number, height: number, url: string,
        options: Object, callback: ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
    name: >-
      generateThumbnail(number, number, string,
      ServiceCallback<stream.Readable>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image.

      A successful response contains the thumbnail image binary. If the request

      failed, the response contains an error code and a message to help
      determine

      what went wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or

      InternalServerError.
    syntax:
      content: >-
        function generateThumbnail(width: number, height: number, url: string,
        callback: ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
    name: 'generateThumbnailInStream(number, number, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image.

      A successful response contains the thumbnail image binary. If the request

      failed, the response contains an error code and a message to help
      determine

      what went wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or

      InternalServerError.
    syntax:
      content: >-
        function generateThumbnailInStream(width: number, height: number, image:
        stream.Readable, options?: Object)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail, in pixels. It must be between
            1 and 1024. Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail, in pixels. It must be
            between 1 and 1024. Recommended minimum of 50.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
    name: >-
      generateThumbnailInStream(number, number, stream.Readable, Object,
      ServiceCallback<stream.Readable>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image.

      A successful response contains the thumbnail image binary. If the request

      failed, the response contains an error code and a message to help
      determine

      what went wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or

      InternalServerError.
    syntax:
      content: >-
        function generateThumbnailInStream(width: number, height: number, image:
        stream.Readable, options: Object, callback:
        ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
    name: >-
      generateThumbnailInStream(number, number, stream.Readable,
      ServiceCallback<stream.Readable>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image.

      A successful response contains the thumbnail image binary. If the request

      failed, the response contains an error code and a message to help
      determine

      what went wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or

      InternalServerError.
    syntax:
      content: >-
        function generateThumbnailInStream(width: number, height: number, image:
        stream.Readable, callback: ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
    name: >-
      generateThumbnailInStreamWithHttpOperationResponse(number, number,
      stream.Readable, Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image.

      A successful response contains the thumbnail image binary. If the request

      failed, the response contains an error code and a message to help
      determine

      what went wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or

      InternalServerError.
    syntax:
      content: >-
        function generateThumbnailInStreamWithHttpOperationResponse(width:
        number, height: number, image: stream.Readable, options?: Object)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail, in pixels. It must be between
            1 and 1024. Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail, in pixels. It must be
            between 1 and 1024. Recommended minimum of 50.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
    name: 'generateThumbnailWithHttpOperationResponse(number, number, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image.

      A successful response contains the thumbnail image binary. If the request

      failed, the response contains an error code and a message to help
      determine

      what went wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or

      InternalServerError.
    syntax:
      content: >-
        function generateThumbnailWithHttpOperationResponse(width: number,
        height: number, url: string, options?: Object)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail, in pixels. It must be between
            1 and 1024. Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail, in pixels. It must be
            between 1 and 1024. Recommended minimum of 50.
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest
    name: 'getAreaOfInterest(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns a bounding box around the most important area of
      the

      image.

      A successful response will be returned in JSON. If the request failed, the

      response contains an error code and a message to help determine what went

      wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
    syntax:
      content: 'function getAreaOfInterest(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_2
    name: 'getAreaOfInterest(string, Object, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns a bounding box around the most important area of
      the

      image.

      A successful response will be returned in JSON. If the request failed, the

      response contains an error code and a message to help determine what went

      wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
    syntax:
      content: >-
        function getAreaOfInterest(url: string, options: Object, callback:
        ServiceCallback<AreaOfInterestResult>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_1
    name: 'getAreaOfInterest(string, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns a bounding box around the most important area of
      the

      image.

      A successful response will be returned in JSON. If the request failed, the

      response contains an error code and a message to help determine what went

      wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
    syntax:
      content: >-
        function getAreaOfInterest(url: string, callback:
        ServiceCallback<AreaOfInterestResult>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream
    name: 'getAreaOfInterestInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns a bounding box around the most important area of
      the

      image.

      A successful response will be returned in JSON. If the request failed, the

      response contains an error code and a message to help determine what went

      wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
    syntax:
      content: >-
        function getAreaOfInterestInStream(image: stream.Readable, options?:
        Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_2
    name: >-
      getAreaOfInterestInStream(stream.Readable, Object,
      ServiceCallback<AreaOfInterestResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns a bounding box around the most important area of
      the

      image.

      A successful response will be returned in JSON. If the request failed, the

      response contains an error code and a message to help determine what went

      wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
    syntax:
      content: >-
        function getAreaOfInterestInStream(image: stream.Readable, options:
        Object, callback: ServiceCallback<AreaOfInterestResult>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_1
    name: >-
      getAreaOfInterestInStream(stream.Readable,
      ServiceCallback<AreaOfInterestResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns a bounding box around the most important area of
      the

      image.

      A successful response will be returned in JSON. If the request failed, the

      response contains an error code and a message to help determine what went

      wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
    syntax:
      content: >-
        function getAreaOfInterestInStream(image: stream.Readable, callback:
        ServiceCallback<AreaOfInterestResult>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStreamWithHttpOperationResponse
    name: >-
      getAreaOfInterestInStreamWithHttpOperationResponse(stream.Readable,
      Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns a bounding box around the most important area of
      the

      image.

      A successful response will be returned in JSON. If the request failed, the

      response contains an error code and a message to help determine what went

      wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
    syntax:
      content: >-
        function getAreaOfInterestInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestWithHttpOperationResponse
    name: 'getAreaOfInterestWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns a bounding box around the most important area of
      the

      image.

      A successful response will be returned in JSON. If the request failed, the

      response contains an error code and a message to help determine what went

      wrong.

      Upon failure, the error code and an error message are returned. The error

      code could be one of InvalidImageUrl, InvalidImageFormat,
      InvalidImageSize,

      NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
    syntax:
      content: >-
        function getAreaOfInterestWithHttpOperationResponse(url: string,
        options?: Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult
    name: 'getReadOperationResult(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting OCR results of Read operation. The URL
      to

      this interface should be retrieved from "Operation-Location" field
      returned

      from Batch Read File interface.
    syntax:
      content: 'function getReadOperationResult(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            Id of read operation returned in the response of
            the "Batch Read File" interface.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_2
    name: >-
      getReadOperationResult(string, Object,
      ServiceCallback<ReadOperationResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting OCR results of Read operation. The URL
      to

      this interface should be retrieved from "Operation-Location" field
      returned

      from Batch Read File interface.
    syntax:
      content: >-
        function getReadOperationResult(operationId: string, options: Object,
        callback: ServiceCallback<ReadOperationResult>)
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_1
    name: 'getReadOperationResult(string, ServiceCallback<ReadOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting OCR results of Read operation. The URL
      to

      this interface should be retrieved from "Operation-Location" field
      returned

      from Batch Read File interface.
    syntax:
      content: >-
        function getReadOperationResult(operationId: string, callback:
        ServiceCallback<ReadOperationResult>)
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResultWithHttpOperationResponse
    name: 'getReadOperationResultWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting OCR results of Read operation. The URL
      to

      this interface should be retrieved from "Operation-Location" field
      returned

      from Batch Read File interface.
    syntax:
      content: >-
        function getReadOperationResultWithHttpOperationResponse(operationId:
        string, options?: Object)
      parameters:
        - id: operationId
          type:
            - string
          description: |
            Id of read operation returned in the response of
            the "Batch Read File" interface.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ReadOperationResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
    name: 'getTextOperationResult(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: 'function getTextOperationResult(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            Id of the text operation returned in the
            response of the 'Recognize Text'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
    name: >-
      getTextOperationResult(string, Object,
      ServiceCallback<TextOperationResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: >-
        function getTextOperationResult(operationId: string, options: Object,
        callback: ServiceCallback<TextOperationResult>)
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
    name: 'getTextOperationResult(string, ServiceCallback<TextOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: >-
        function getTextOperationResult(operationId: string, callback:
        ServiceCallback<TextOperationResult>)
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
    name: 'getTextOperationResultWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: >-
        function getTextOperationResultWithHttpOperationResponse(operationId:
        string, options?: Object)
      parameters:
        - id: operationId
          type:
            - string
          description: |
            Id of the text operation returned in the
            response of the 'Recognize Text'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels
    name: listModels(Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API. Currently, the API supports following

      domain-specific models: celebrity recognizer, landmark recognizer.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function listModels(options?: Object)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
    name: 'listModels(Object, ServiceCallback<ListModelsResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API. Currently, the API supports following

      domain-specific models: celebrity recognizer, landmark recognizer.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function listModels(options: Object, callback:
        ServiceCallback<ListModelsResult>)
      parameters:
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
    name: listModels(ServiceCallback<ListModelsResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API. Currently, the API supports following

      domain-specific models: celebrity recognizer, landmark recognizer.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
      parameters:
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
    name: listModelsWithHttpOperationResponse(Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API. Currently, the API supports following

      domain-specific models: celebrity recognizer, landmark recognizer.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function listModelsWithHttpOperationResponse(options?: Object)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
    name: 'recognizePrintedText(boolean, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects text in an image and extracts

      the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned.

      Upon failure, the error code together with an error message will be

      returned. The error code can be one of InvalidImageUrl,
      InvalidImageFormat,

      InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or

      InternalServerError.
    syntax:
      content: >-
        function recognizePrintedText(detectOrientation: boolean, url: string,
        options?: Object)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
    name: 'recognizePrintedText(boolean, string, Object, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects text in an image and extracts

      the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned.

      Upon failure, the error code together with an error message will be

      returned. The error code can be one of InvalidImageUrl,
      InvalidImageFormat,

      InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or

      InternalServerError.
    syntax:
      content: >-
        function recognizePrintedText(detectOrientation: boolean, url: string,
        options: Object, callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
    name: 'recognizePrintedText(boolean, string, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects text in an image and extracts

      the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned.

      Upon failure, the error code together with an error message will be

      returned. The error code can be one of InvalidImageUrl,
      InvalidImageFormat,

      InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or

      InternalServerError.
    syntax:
      content: >-
        function recognizePrintedText(detectOrientation: boolean, url: string,
        callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects text in an image and extracts

      the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned.

      Upon failure, the error code together with an error message will be

      returned. The error code can be one of InvalidImageUrl,
      InvalidImageFormat,

      InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or

      InternalServerError.
    syntax:
      content: >-
        function recognizePrintedTextInStream(detectOrientation: boolean, image:
        stream.Readable, options?: Object)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
    name: >-
      recognizePrintedTextInStream(boolean, stream.Readable, Object,
      ServiceCallback<OcrResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects text in an image and extracts

      the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned.

      Upon failure, the error code together with an error message will be

      returned. The error code can be one of InvalidImageUrl,
      InvalidImageFormat,

      InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or

      InternalServerError.
    syntax:
      content: >-
        function recognizePrintedTextInStream(detectOrientation: boolean, image:
        stream.Readable, options: Object, callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
    name: >-
      recognizePrintedTextInStream(boolean, stream.Readable,
      ServiceCallback<OcrResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects text in an image and extracts

      the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned.

      Upon failure, the error code together with an error message will be

      returned. The error code can be one of InvalidImageUrl,
      InvalidImageFormat,

      InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or

      InternalServerError.
    syntax:
      content: >-
        function recognizePrintedTextInStream(detectOrientation: boolean, image:
        stream.Readable, callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
    name: >-
      recognizePrintedTextInStreamWithHttpOperationResponse(boolean,
      stream.Readable, Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects text in an image and extracts

      the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned.

      Upon failure, the error code together with an error message will be

      returned. The error code can be one of InvalidImageUrl,
      InvalidImageFormat,

      InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or

      InternalServerError.
    syntax:
      content: >-
        function
        recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation:
        boolean, image: stream.Readable, options?: Object)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
    name: 'recognizePrintedTextWithHttpOperationResponse(boolean, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects text in an image and extracts

      the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned.

      Upon failure, the error code together with an error message will be

      returned. The error code can be one of InvalidImageUrl,
      InvalidImageFormat,

      InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or

      InternalServerError.
    syntax:
      content: >-
        function
        recognizePrintedTextWithHttpOperationResponse(detectOrientation:
        boolean, url: string, options?: Object)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
    name: 'recognizeText(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: 'function recognizeText(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
    name: 'recognizeText(string, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeText(url: string, mode: string, options: Object,
        callback: ServiceCallback<void>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
    name: 'recognizeText(string, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeText(url: string, mode: string, callback:
        ServiceCallback<void>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
    name: 'recognizeTextInStream(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStream(image: stream.Readable, mode: string,
        options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
    name: >-
      recognizeTextInStream(stream.Readable, string, Object,
      ServiceCallback<void>)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStream(image: stream.Readable, mode: string,
        options: Object, callback: ServiceCallback<void>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
    name: 'recognizeTextInStream(stream.Readable, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStream(image: stream.Readable, mode: string,
        callback: ServiceCallback<void>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
    name: >-
      recognizeTextInStreamWithHttpOperationResponse(stream.Readable, string,
      Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStreamWithHttpOperationResponse(image:
        stream.Readable, mode: string, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
    name: 'recognizeTextWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called 'Operation-Location'. The
      'Operation-Location' field contains the URL that you must use for your Get
      Recognize Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextWithHttpOperationResponse(url: string, mode:
        string, options?: Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: mode
          type:
            - string
          description: |
            Type of text to recognize. Possible values include:
            'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
    name: 'tagImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag "cello"
      may

      be accompanied by the hint "musical instrument". All tags are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function tagImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
    name: 'tagImage(string, Object, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag "cello"
      may

      be accompanied by the hint "musical instrument". All tags are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function tagImage(url: string, options: Object, callback:
        ServiceCallback<TagResult>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
    name: 'tagImage(string, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag "cello"
      may

      be accompanied by the hint "musical instrument". All tags are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
    name: 'tagImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag "cello"
      may

      be accompanied by the hint "musical instrument". All tags are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
    name: 'tagImageInStream(stream.Readable, Object, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag "cello"
      may

      be accompanied by the hint "musical instrument". All tags are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function tagImageInStream(image: stream.Readable, options: Object,
        callback: ServiceCallback<TagResult>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
    name: 'tagImageInStream(stream.Readable, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag "cello"
      may

      be accompanied by the hint "musical instrument". All tags are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function tagImageInStream(image: stream.Readable, callback:
        ServiceCallback<TagResult>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
    name: 'tagImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag "cello"
      may

      be accompanied by the hint "musical instrument". All tags are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function tagImageInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
    name: 'tagImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag "cello"
      may

      be accompanied by the hint "musical instrument". All tags are in English.

      Two input methods are supported -- (1) Uploading an image or (2)
      specifying

      an image URL.

      A successful response will be returned in JSON. If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function tagImageWithHttpOperationResponse(url: string, options?:
        Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
references:
  - uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    name: ImageAnalysis>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
    name: ImageAnalysis>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
    name: DomainModelResults>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
    name: DomainModelResults>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    name: DomainModelResults>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>>'
        fullName: '>>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    name: ImageAnalysis>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
    name: ImageDescription>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
    name: ImageDescription>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    name: ImageDescription>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.DetectResult>
    name: DetectResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
    name: DetectResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    name: DetectResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    name: AreaOfInterestResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>'
        fullName: '>'
  - uid: >-
      ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
    name: AreaOfInterestResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    name: AreaOfInterestResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    name: ReadOperationResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>'
        fullName: '>'
  - uid: >-
      ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
    name: ReadOperationResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ReadOperationResult>>
    name: ReadOperationResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
    name: TextOperationResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: >-
      ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
    name: TextOperationResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    name: TextOperationResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
    name: ListModelsResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
    name: ListModelsResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    name: ListModelsResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.OcrResult>
    name: OcrResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
    name: OcrResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    name: OcrResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TagResult>
    name: TagResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
    name: TagResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    name: TagResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>>'
        fullName: '>>'

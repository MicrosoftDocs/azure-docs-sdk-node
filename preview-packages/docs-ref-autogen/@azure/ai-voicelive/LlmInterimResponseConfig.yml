### YamlMime:TSType
name: LlmInterimResponseConfig
uid: '@azure/ai-voicelive.LlmInterimResponseConfig'
package: '@azure/ai-voicelive'
summary: >-
  Configuration for LLM-based interim response generation.

  Uses LLM to generate context-aware interim responses when any trigger
  condition is met.
fullName: LlmInterimResponseConfig
remarks: ''
isDeprecated: false
type: interface
properties:
  - name: instructions
    uid: '@azure/ai-voicelive.LlmInterimResponseConfig.instructions'
    package: '@azure/ai-voicelive'
    summary: >-
      Custom instructions for generating interim responses. If not provided, a
      default prompt is used.
    fullName: instructions
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'instructions?: string'
      return:
        description: ''
        type: string
  - name: maxCompletionTokens
    uid: '@azure/ai-voicelive.LlmInterimResponseConfig.maxCompletionTokens'
    package: '@azure/ai-voicelive'
    summary: Maximum number of tokens to generate for the interim response.
    fullName: maxCompletionTokens
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'maxCompletionTokens?: number'
      return:
        description: ''
        type: number
  - name: model
    uid: '@azure/ai-voicelive.LlmInterimResponseConfig.model'
    package: '@azure/ai-voicelive'
    summary: >-
      The model to use for LLM-based interim response generation. Default is
      gpt-4.1-mini.
    fullName: model
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'model?: string'
      return:
        description: ''
        type: string
  - name: type
    uid: '@azure/ai-voicelive.LlmInterimResponseConfig.type'
    package: '@azure/ai-voicelive'
    summary: >-
      The discriminator possible values: static_interim_response,
      llm_interim_response
    fullName: type
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'type: "llm_interim_response"'
      return:
        description: ''
        type: '"llm_interim_response"'
inheritedProperties:
  - name: latencyThresholdInMs
    uid: '@azure/ai-voicelive.LlmInterimResponseConfig.latencyThresholdInMs'
    package: '@azure/ai-voicelive'
    summary: >-
      Latency threshold in milliseconds before triggering interim response.
      Default is 2000ms.
    fullName: latencyThresholdInMs
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'latencyThresholdInMs?: number'
      return:
        description: ''
        type: number
    inheritanceDescription: >-
      <b>Inherited From</b>
      [InterimResponseConfigBase.latencyThresholdInMs](xref:@azure/ai-voicelive.InterimResponseConfigBase.latencyThresholdInMs)
  - name: triggers
    uid: '@azure/ai-voicelive.LlmInterimResponseConfig.triggers'
    package: '@azure/ai-voicelive'
    summary: >-
      List of triggers that can fire the interim response. Any trigger can
      activate it (OR logic).

      Supported: 'latency', 'tool'.
    fullName: triggers
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'triggers?: string[]'
      return:
        description: ''
        type: string[]
    inheritanceDescription: >-
      <b>Inherited From</b>
      [InterimResponseConfigBase.triggers](xref:@azure/ai-voicelive.InterimResponseConfigBase.triggers)
extends: <xref uid="@azure/ai-voicelive.InterimResponseConfigBase" />

### YamlMime:UniversalReference
items:
  - uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient
    name: ComputerVisionAPIClient
    fullName: ComputerVisionAPIClient
    children:
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.azureRegion
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.constructor
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.credentials
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResultWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModelsWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_1
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_2
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStreamWithHttpOperationResponse
      - >-
        azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageWithHttpOperationResponse
    langs:
      - typeScript
    type: class
    summary: ''
    extends:
      name: ServiceClient
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage
    name: analyzeImage
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content. Two input methods are supported -- (1) Uploading an image or (2)
      specifying an image URL.  Within your request, there is an optional
      parameter to allow you to choose which features to return.  By default,
      image categories are returned in the response.
    syntax:
      content: 'function analyzeImage(url: string, options?: function)'
      parameters:
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_2
    name: analyzeImage
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content. Two input methods are supported -- (1) Uploading an image or (2)
      specifying an image URL.  Within your request, there is an optional
      parameter to allow you to choose which features to return.  By default,
      image categories are returned in the response.
    syntax:
      content: >-
        function analyzeImage(url: string, options: function, callback:
        ServiceCallback<ImageAnalysis>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_1
    name: analyzeImage
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content. Two input methods are supported -- (1) Uploading an image or (2)
      specifying an image URL.  Within your request, there is an optional
      parameter to allow you to choose which features to return.  By default,
      image categories are returned in the response.
    syntax:
      content: >-
        function analyzeImage(url: string, callback:
        ServiceCallback<ImageAnalysis>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain
    name: analyzeImageByDomain
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomain(model: string, url: string, options?:
        function)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize. Possible
            values include: 'Celebrities', 'Landmarks'
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_1
    name: analyzeImageByDomain
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomain(model: string, url: string, callback:
        ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_2
    name: analyzeImageByDomain
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomain(model: string, url: string, options:
        function, callback: ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream
    name: analyzeImageByDomainInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStream(model: string, image:
        stream.Readable, options?: function)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_1
    name: analyzeImageByDomainInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStream(model: string, image:
        stream.Readable, callback: ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_2
    name: analyzeImageByDomainInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStream(model: string, image:
        stream.Readable, options: function, callback:
        ServiceCallback<DomainModelResults>)
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStreamWithHttpOperationResponse
    name: analyzeImageByDomainInStreamWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainInStreamWithHttpOperationResponse(model:
        string, image: stream.Readable, options?: function)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainWithHttpOperationResponse
    name: analyzeImageByDomainWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation recognizes content within an image by applying a

      domain-specific model.  The list of domain-specific models that are

      supported by the Computer Vision API can be retrieved using the /models
      GET

      request.  Currently, the API only provides a single domain-specific model:

      celebrities. Two input methods are supported -- (1) Uploading an image or

      (2) specifying an image URL. A successful response will be returned in
      JSON.

      If the request failed, the response will contain an error code and a
      message

      to help understand what went wrong.
    syntax:
      content: >-
        function analyzeImageByDomainWithHttpOperationResponse(model: string,
        url: string, options?: function)
      parameters:
        - id: model
          type:
            - string
          description: |
            The domain-specific content to recognize. Possible
            values include: 'Celebrities', 'Landmarks'
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream
    name: analyzeImageInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content.
    syntax:
      content: >-
        function analyzeImageInStream(image: stream.Readable, options?:
        function)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_1
    name: analyzeImageInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content.
    syntax:
      content: >-
        function analyzeImageInStream(image: stream.Readable, callback:
        ServiceCallback<ImageAnalysis>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_2
    name: analyzeImageInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content.
    syntax:
      content: >-
        function analyzeImageInStream(image: stream.Readable, options: function,
        callback: ServiceCallback<ImageAnalysis>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStreamWithHttpOperationResponse
    name: analyzeImageInStreamWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content.
    syntax:
      content: >-
        function analyzeImageInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: function)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageWithHttpOperationResponse
    name: analyzeImageWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      This operation extracts a rich set of visual features based on the image
      content. Two input methods are supported -- (1) Uploading an image or (2)
      specifying an image URL.  Within your request, there is an optional
      parameter to allow you to choose which features to return.  By default,
      image categories are returned in the response.
    syntax:
      content: >-
        function analyzeImageWithHttpOperationResponse(url: string, options?:
        function)
      parameters:
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.azureRegion
    name: azureRegion
    fullName: azureRegion
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'azureRegion: string'
      return:
        type:
          - string
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.constructor
    name: ComputerVisionAPIClient
    children: []
    type: constructor
    langs:
      - typeScript
    summary: ''
    syntax:
      content: >-
        new ComputerVisionAPIClient(credentials: ServiceClientCredentials,
        azureRegion: string, options?: ServiceClientOptions)
      parameters:
        - id: credentials
          type:
            - ServiceClientCredentials
          description: >
            Subscription credentials which uniquely identify client
            subscription.
        - id: azureRegion
          type:
            - string
          description: >
            Supported Azure regions for Cognitive Services endpoints. Possible
            values include: 'westus', 'westeurope', 'southeastasia', 'eastus2',
            'westcentralus', 'westus2', 'eastus', 'southcentralus',
            'northeurope', 'eastasia', 'australiaeast', 'brazilsouth'
        - id: options
          type:
            - ServiceClientOptions
          description: ''
          optional: true
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.credentials
    name: credentials
    fullName: credentials
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'credentials: ServiceClientCredentials'
      return:
        type:
          - ServiceClientCredentials
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_1
    name: describeImage
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImage(url: string, callback:
        ServiceCallback<ImageDescription>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage
    name: describeImage
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: 'function describeImage(url: string, options?: function)'
      parameters:
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_2
    name: describeImage
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImage(url: string, options: function, callback:
        ServiceCallback<ImageDescription>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream
    name: describeImageInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageInStream(image: stream.Readable, options?:
        function)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_1
    name: describeImageInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageInStream(image: stream.Readable, callback:
        ServiceCallback<ImageDescription>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_2
    name: describeImageInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageInStream(image: stream.Readable, options:
        function, callback: ServiceCallback<ImageDescription>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStreamWithHttpOperationResponse
    name: describeImageInStreamWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: function)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageWithHttpOperationResponse
    name: describeImageWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a description of an image in human readable

      language with complete sentences.  The description is based on a
      collection

      of content tags, which are also returned by the operation. More than one

      description can be generated for each image.  Descriptions are ordered by

      their confidence score. All descriptions are in English. Two input methods

      are supported -- (1) Uploading an image or (2) specifying an image URL.A

      successful response will be returned in JSON.  If the request failed, the

      response will contain an error code and a message to help understand what

      went wrong.
    syntax:
      content: >-
        function describeImageWithHttpOperationResponse(url: string, options?:
        function)
      parameters:
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_1
    name: generateThumbnail
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnail(width: number, height: number, url: string,
        callback: ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_2
    name: generateThumbnail
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnail(width: number, height: number, url: string,
        options: function, callback: ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail
    name: generateThumbnail
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnail(width: number, height: number, url: string,
        options?: function)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail. It must be between 1 and 1024.
            Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail. It must be between 1 and
            1024. Recommended minimum of 50.
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream
    name: generateThumbnailInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnailInStream(width: number, height: number, image:
        stream.Readable, options?: function)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail. It must be between 1 and 1024.
            Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail. It must be between 1 and
            1024. Recommended minimum of 50.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_1
    name: generateThumbnailInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnailInStream(width: number, height: number, image:
        stream.Readable, callback: ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_2
    name: generateThumbnailInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnailInStream(width: number, height: number, image:
        stream.Readable, options: function, callback:
        ServiceCallback<stream.Readable>)
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStreamWithHttpOperationResponse
    name: generateThumbnailInStreamWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnailInStreamWithHttpOperationResponse(width:
        number, height: number, image: stream.Readable, options?: function)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail. It must be between 1 and 1024.
            Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail. It must be between 1 and
            1024. Recommended minimum of 50.
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailWithHttpOperationResponse
    name: generateThumbnailWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a thumbnail image with the user-specified width
      and

      height. By default, the service analyzes the image, identifies the region
      of

      interest (ROI), and generates smart cropping coordinates based on the ROI.

      Smart cropping helps when you specify an aspect ratio that differs from
      that

      of the input image. A successful response contains the thumbnail image

      binary. If the request failed, the response contains an error code and a

      message to help determine what went wrong.
    syntax:
      content: >-
        function generateThumbnailWithHttpOperationResponse(width: number,
        height: number, url: string, options?: function)
      parameters:
        - id: width
          type:
            - number
          description: |
            Width of the thumbnail. It must be between 1 and 1024.
            Recommended minimum of 50.
        - id: height
          type:
            - number
          description: |
            Height of the thumbnail. It must be between 1 and
            1024. Recommended minimum of 50.
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult
    name: getTextOperationResult
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: 'function getTextOperationResult(operationId: string, options?: function)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            Id of the text operation returned in the
            response of the 'Recognize Handwritten Text'
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_2
    name: getTextOperationResult
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: >-
        function getTextOperationResult(operationId: string, options: function,
        callback: ServiceCallback<TextOperationResult>)
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_1
    name: getTextOperationResult
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: >-
        function getTextOperationResult(operationId: string, callback:
        ServiceCallback<TextOperationResult>)
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResultWithHttpOperationResponse
    name: getTextOperationResultWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This interface is used for getting text operation result. The URL to this

      interface should be retrieved from 'Operation-Location' field returned
      from

      Recognize Text interface.
    syntax:
      content: >-
        function getTextOperationResultWithHttpOperationResponse(operationId:
        string, options?: function)
      parameters:
        - id: operationId
          type:
            - string
          description: |
            Id of the text operation returned in the
            response of the 'Recognize Handwritten Text'
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels
    name: listModels
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API.  Currently, the API only supports one

      domain-specific model: a celebrity recognizer. A successful response will
      be

      returned in JSON.  If the request failed, the response will contain an
      error

      code and a message to help understand what went wrong.
    syntax:
      content: 'function listModels(options?: function)'
      parameters:
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_2
    name: listModels
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API.  Currently, the API only supports one

      domain-specific model: a celebrity recognizer. A successful response will
      be

      returned in JSON.  If the request failed, the response will contain an
      error

      code and a message to help understand what went wrong.
    syntax:
      content: >-
        function listModels(options: function, callback:
        ServiceCallback<ListModelsResult>)
      parameters:
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_1
    name: listModels
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API.  Currently, the API only supports one

      domain-specific model: a celebrity recognizer. A successful response will
      be

      returned in JSON.  If the request failed, the response will contain an
      error

      code and a message to help understand what went wrong.
    syntax:
      content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
      parameters:
        - id: callback
          type:
            - >-
              ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModelsWithHttpOperationResponse
    name: listModelsWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation returns the list of domain-specific models that are
      supported

      by the Computer Vision API.  Currently, the API only supports one

      domain-specific model: a celebrity recognizer. A successful response will
      be

      returned in JSON.  If the request failed, the response will contain an
      error

      code and a message to help understand what went wrong.
    syntax:
      content: 'function listModelsWithHttpOperationResponse(options?: function)'
      parameters:
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_1
    name: recognizePrintedText
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedText(detectOrientation: boolean, url: string,
        callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText
    name: recognizePrintedText
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedText(detectOrientation: boolean, url: string,
        options?: function)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_2
    name: recognizePrintedText
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedText(detectOrientation: boolean, url: string,
        options: function, callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream
    name: recognizePrintedTextInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedTextInStream(detectOrientation: boolean, image:
        stream.Readable, options?: function)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_1
    name: recognizePrintedTextInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedTextInStream(detectOrientation: boolean, image:
        stream.Readable, callback: ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_2
    name: recognizePrintedTextInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function recognizePrintedTextInStream(detectOrientation: boolean, image:
        stream.Readable, options: function, callback:
        ServiceCallback<OcrResult>)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStreamWithHttpOperationResponse
    name: recognizePrintedTextInStreamWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function
        recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation:
        boolean, image: stream.Readable, options?: function)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextWithHttpOperationResponse
    name: recognizePrintedTextWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Optical Character Recognition (OCR) detects printed text in an image and

      extracts the recognized characters into a machine-usable character stream.

      Upon success, the OCR results will be returned. Upon failure, the error
      code

      together with an error message will be returned. The error code can be one

      of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
      NotSupportedImage,

      NotSupportedLanguage, or InternalServerError.
    syntax:
      content: >-
        function
        recognizePrintedTextWithHttpOperationResponse(detectOrientation:
        boolean, url: string, options?: function)
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: >
            Whether detect the text orientation in

            the image. With detectOrientation=true the OCR service tries to
            detect the

            image orientation and correct it before further processing (e.g. if
            it's

            upside-down).
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText
    name: recognizeText
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called Operation-Location. The
      Operation-Location field contains the URL that you must use for your Get
      Handwritten Text Operation Result operation.
    syntax:
      content: 'function recognizeText(url: string, options?: function)'
      parameters:
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_2
    name: recognizeText
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called Operation-Location. The
      Operation-Location field contains the URL that you must use for your Get
      Handwritten Text Operation Result operation.
    syntax:
      content: >-
        function recognizeText(url: string, options: function, callback:
        ServiceCallback<void>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_1
    name: recognizeText
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called Operation-Location. The
      Operation-Location field contains the URL that you must use for your Get
      Handwritten Text Operation Result operation.
    syntax:
      content: 'function recognizeText(url: string, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream
    name: recognizeTextInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called Operation-Location. The
      Operation-Location field contains the URL that you must use for your Get
      Handwritten Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStream(image: stream.Readable, options?:
        function)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_1
    name: recognizeTextInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called Operation-Location. The
      Operation-Location field contains the URL that you must use for your Get
      Handwritten Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStream(image: stream.Readable, callback:
        ServiceCallback<void>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_2
    name: recognizeTextInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called Operation-Location. The
      Operation-Location field contains the URL that you must use for your Get
      Handwritten Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStream(image: stream.Readable, options:
        function, callback: ServiceCallback<void>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStreamWithHttpOperationResponse
    name: recognizeTextInStreamWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called Operation-Location. The
      Operation-Location field contains the URL that you must use for your Get
      Handwritten Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: function)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextWithHttpOperationResponse
    name: recognizeTextWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Recognize Text operation. When you use the Recognize Text interface, the
      response contains a field called Operation-Location. The
      Operation-Location field contains the URL that you must use for your Get
      Handwritten Text Operation Result operation.
    syntax:
      content: >-
        function recognizeTextWithHttpOperationResponse(url: string, options?:
        function)
      parameters:
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage
    name: tagImage
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag cello
      may

      be accompanied by the hint musical instrument. All tags are in English.
    syntax:
      content: 'function tagImage(url: string, options?: function)'
      parameters:
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_1
    name: tagImage
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag cello
      may

      be accompanied by the hint musical instrument. All tags are in English.
    syntax:
      content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_2
    name: tagImage
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag cello
      may

      be accompanied by the hint musical instrument. All tags are in English.
    syntax:
      content: >-
        function tagImage(url: string, options: function, callback:
        ServiceCallback<TagResult>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream
    name: tagImageInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag cello
      may

      be accompanied by the hint musical instrument. All tags are in English.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, options?: function)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_1
    name: tagImageInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag cello
      may

      be accompanied by the hint musical instrument. All tags are in English.
    syntax:
      content: >-
        function tagImageInStream(image: stream.Readable, callback:
        ServiceCallback<TagResult>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_2
    name: tagImageInStream
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag cello
      may

      be accompanied by the hint musical instrument. All tags are in English.
    syntax:
      content: >-
        function tagImageInStream(image: stream.Readable, options: function,
        callback: ServiceCallback<TagResult>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - function
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStreamWithHttpOperationResponse
    name: tagImageInStreamWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag cello
      may

      be accompanied by the hint musical instrument. All tags are in English.
    syntax:
      content: >-
        function tagImageInStreamWithHttpOperationResponse(image:
        stream.Readable, options?: function)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
  - uid: >-
      azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageWithHttpOperationResponse
    name: tagImageWithHttpOperationResponse
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      This operation generates a list of words, or tags, that are relevant to
      the

      content of the supplied image. The Computer Vision API can return tags
      based

      on objects, living beings, scenery or actions found in images. Unlike

      categories, tags are not organized according to a hierarchical

      classification system, but correspond to image content. Tags may contain

      hints to avoid ambiguity or provide context, for example the tag cello
      may

      be accompanied by the hint musical instrument. All tags are in English.
    syntax:
      content: >-
        function tagImageWithHttpOperationResponse(url: string, options?:
        function)
      parameters:
        - id: url
          type:
            - string
          description: |+

        - id: options
          type:
            - function
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
references:
  - uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>>'
        fullName: '>>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: >-
      ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.OcrResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TagResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>>'
        fullName: '>>'

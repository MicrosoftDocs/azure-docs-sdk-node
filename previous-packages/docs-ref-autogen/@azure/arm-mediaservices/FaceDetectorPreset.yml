### YamlMime:TSType
name: FaceDetectorPreset
uid: '@azure/arm-mediaservices.FaceDetectorPreset'
package: '@azure/arm-mediaservices'
summary: >-
  Describes all the settings to be used when analyzing a video in order to
  detect (and optionally redact) all the faces present.
fullName: FaceDetectorPreset
remarks: ''
isDeprecated: false
type: interface
properties:
  - name: blurType
    uid: '@azure/arm-mediaservices.FaceDetectorPreset.blurType'
    package: '@azure/arm-mediaservices'
    summary: Blur type
    fullName: blurType
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'blurType?: string'
      return:
        description: ''
        type: string
  - name: experimentalOptions
    uid: '@azure/arm-mediaservices.FaceDetectorPreset.experimentalOptions'
    package: '@azure/arm-mediaservices'
    summary: >-
      Dictionary containing key value pairs for parameters not exposed in the
      preset itself
    fullName: experimentalOptions
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'experimentalOptions?: {[propertyName: string]: string}'
      return:
        description: ''
        type: '{[propertyName: string]: string}'
  - name: mode
    uid: '@azure/arm-mediaservices.FaceDetectorPreset.mode'
    package: '@azure/arm-mediaservices'
    summary: >-
      This mode provides the ability to choose between the following settings:
      1) Analyze - For detection only.This mode generates a metadata JSON file
      marking appearances of faces throughout the video.Where possible,
      appearances of the same person are assigned the same ID. 2) Combined -
      Additionally redacts(blurs) detected faces. 3) Redact - This enables a
      2-pass process, allowing for selective redaction of a subset of detected
      faces.It takes in the metadata file from a prior analyze pass, along with
      the source video, and a user-selected subset of IDs that require
      redaction.
    fullName: mode
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'mode?: string'
      return:
        description: ''
        type: string
  - name: odataType
    uid: '@azure/arm-mediaservices.FaceDetectorPreset.odataType'
    package: '@azure/arm-mediaservices'
    summary: >-
      Polymorphic discriminator, which specifies the different types this object
      can be
    fullName: odataType
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'odataType: "#Microsoft.Media.FaceDetectorPreset"'
      return:
        description: ''
        type: '"#<xref uid="Microsoft.Media.FaceDetectorPreset" />"'
  - name: resolution
    uid: '@azure/arm-mediaservices.FaceDetectorPreset.resolution'
    package: '@azure/arm-mediaservices'
    summary: >-
      Specifies the maximum resolution at which your video is analyzed. The
      default behavior is "SourceResolution," which will keep the input video at
      its original resolution when analyzed. Using "StandardDefinition" will
      resize input videos to standard definition while preserving the
      appropriate aspect ratio. It will only resize if the video is of higher
      resolution. For example, a 1920x1080 input would be scaled to 640x360
      before processing. Switching to "StandardDefinition" will reduce the time
      it takes to process high resolution video. It may also reduce the cost of
      using this component (see
      https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics
      for details). However, faces that end up being too small in the resized
      video may not be detected.
    fullName: resolution
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'resolution?: string'
      return:
        description: ''
        type: string
extends: <xref uid="@azure/arm-mediaservices.Preset" />

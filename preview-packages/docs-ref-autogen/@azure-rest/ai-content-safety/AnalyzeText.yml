### YamlMime:TSType
name: AnalyzeText
uid: '@azure-rest/ai-content-safety.AnalyzeText'
package: '@azure-rest/ai-content-safety'
summary: ''
fullName: AnalyzeText
remarks: ''
isDeprecated: false
type: interface
methods:
  - name: post(AnalyzeTextParameters)
    uid: '@azure-rest/ai-content-safety.AnalyzeText.post'
    package: '@azure-rest/ai-content-safety'
    summary: >-
      A synchronous API for the analysis of potentially harmful text content.
      Currently, it supports four categories: Hate, SelfHarm, Sexual, and
      Violence.
    remarks: ''
    isDeprecated: false
    syntax:
      content: >-
        function post(options: AnalyzeTextParameters):
        StreamableMethod<AnalyzeText200Response | AnalyzeTextDefaultResponse>
      parameters:
        - id: options
          type: <xref uid="@azure-rest/ai-content-safety.AnalyzeTextParameters" />
          description: ''
      return:
        description: ''
        type: >-
          <xref uid="@azure-rest/core-client.StreamableMethod" />&lt;<xref
          uid="@azure-rest/ai-content-safety.AnalyzeText200Response" /> | <xref
          uid="@azure-rest/ai-content-safety.AnalyzeTextDefaultResponse" />&gt;

### YamlMime:TSTypeAlias
name: EdgeNGramTokenizer
uid: '@azure/search-documents.EdgeNGramTokenizer'
package: '@azure/search-documents'
summary: >-
  Tokenizes the input from an edge into n-grams of the given size(s). This
  tokenizer is implemented using Apache Lucene.
fullName: EdgeNGramTokenizer
remarks: ''
isPreview: false
isDeprecated: false
syntax: >-
  type EdgeNGramTokenizer = BaseLexicalTokenizer & { maxGram: number, minGram:
  number, odatatype: #Microsoft.Azure.Search.EdgeNGramTokenizer, tokenChars:
  Object }
